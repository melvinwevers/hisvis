
@article{loshchilov_decoupled_2019,
  title = {Decoupled {{Weight Decay Regularization}}},
  author = {Loshchilov, Ilya and Hutter, Frank},
  year = {2019},
  month = jan,
  archivePrefix = {arXiv},
  eprint = {1711.05101},
  eprinttype = {arxiv},
  journal = {arXiv:1711.05101 [cs, math]},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Mathematics - Optimization and Control},
  primaryClass = {cs, math}
}


@article{oliva_modeling_2001,
  title = {Modeling the Shape of the Scene: {{A}} Holistic Representation of the Spatial Envelope},
  shorttitle = {Modeling the Shape of the Scene},
  author = {Oliva, Aude and Torralba, Antonio},
  year = {2001},
  volume = {42},
  pages = {145--175},
  publisher = {{Springer}},
  file = {/Users/melvinwevers/Dropbox/zotero/Oliva_Torralba_2001_Modeling the shape of the scene.pdf;/Users/melvinwevers/Zotero/storage/GSFLK8YY/A1011139631724.html},
  journal = {International journal of computer vision},
  number = {3}
}

@inproceedings{xiao2010sun,
  title={Sun database: Large-scale scene recognition from abbey to zoo},
  author={Xiao, Jianxiong and Hays, James and Ehinger, Krista A and Oliva, Aude and Torralba, Antonio},
  booktitle={2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  pages={3485--3492},
  year={2010},
  organization={IEEE}
}


@inproceedings{bhargav_deep_2019,
  title = {Deep {{Learning}} as a {{Tool}} for {{Early Cinema Analysis}}},
  booktitle = {Proceedings of the 1st {{Workshop}} on {{Structuring}} and {{Understanding}} of {{Multimedia heritage Contents}}},
  author = {Bhargav, Samarth and {van Noord}, Nanne and Kamps, Jaap},
  year = {2019},
  month = oct,
  pages = {61--68},
  publisher = {{Association for Computing Machinery}},
  address = {{Nice, France}},
  doi = {10.1145/3347317.3357240},
  abstract = {Visual Cultural Heritage has extensively been explored using multimedia methods, but has so far been limited to still images. In particular, Early Cinema has hardly been explored. We analyze the Desmet collection, a recently digitized collection of early cinema (1907-1916), in the context of intertitles. Intertitles played an important role in silent movies in order to convey the main narratives, and split the film into semantically meaningful segments. We first build several classifiers to detect these intertitles, and evaluate it on a gold standard collection annotated by an expert. We illustrate the usefulness of using Deep Learning methods to extract semantic features to analyze the role of intertitles in early cinema. Furthermore, we attempt to structure and map the narrative progression of a film with respect to the locations at which shots were filmed.},
  file = {/Users/melvinwevers/Dropbox/zotero/Bhargav et al_2019_Deep Learning as a Tool for Early Cinema Analysis.pdf},
  isbn = {978-1-4503-6910-7},
  keywords = {deep learning,early cinema,visual cultural heritage},
  series = {{{SUMAC}} '19}
}


@book{bell_computing_2018,
  title = {Computing {{Art Reader}}: {{Einf\"uhrung}} in Die Digitale {{Kunstgeschichte}}, {{P}}. {{Kuroczy\'nski}} et al. (Ed.)},
  shorttitle = {Computing {{Art Reader}}},
  author = {Bell, P. and Ommer, Bj{\"o}rn and Ommer, Bj{\"o}rn and Ommer, Bj{\"o}rn},
  year = {2018},
  file = {/Users/melvinwevers/Zotero/storage/SK49882J/prof-ommer.html}
}


@incollection{mager_visual_2020,
  title = {Visual {{Content Analysis}} and {{Linked Data}} for {{Automatic Enrichment}} of {{Architecture}}-{{Related Images}}},
  booktitle = {Digital {{Cultural Heritage}}},
  author = {Mager, Tino and Khademi, Seyran and Siebes, Ronald and Hein, Carola and de Boer, Victor and van Gemert, Jan},
  editor = {Kremers, Horst},
  year = {2020},
  pages = {279--293},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-15200-0_18},
  abstract = {Built form dominates the urban space where most people live and work and provides a visual reflection of the local, regional and global esthetical, social, cultural, technological and economic factors and values. Street-view images and historical photo archives are therefore an invaluable source for sociological or historical study; however, they often lack metadata to start any comparative analysis. Date and location are two basic annotations often missing from historical images. Depending on the research question other annotations might be useful, that either could be visually derived (e.g. the number or age of cars, the fashion people wear, the amount of street decay) or extracted from other data sources (e.g. crime statistics for the neighborhood where the picture was taken). Recent advances in automatic visual analysis and the increasing amount of linked open data triggered the research described in this paper. We provide an overview of the current status of automated image analysis and linked data technology and present a case study and methodology to automatically enrich a large database of historical images of buildings in the city of Amsterdam.},
  isbn = {978-3-030-15200-0},
  keywords = {Architectural heritage,Architectural history,Automated image analysis,Computer vision,Linked open data},
  language = {en}
}



@incollection{niebling_analyzing_2020,
  title = {Analyzing {{Spatial Distribution}} of {{Photographs}} in {{Cultural Heritage Applications}}},
  booktitle = {Visual {{Computing}} for {{Cultural Heritage}}},
  author = {Niebling, Florian and Bruschke, Jonas and Messemer, Heike and Wacker, Markus and {von Mammen}, Sebastian},
  editor = {Liarokapis, Fotis and Voulodimos, Athanasios and Doulamis, Nikolaos and Doulamis, Anastasios},
  year = {2020},
  pages = {391--408},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-37191-3_20},
  abstract = {Digitized historical photographs are invaluable sources and key items for scholars in Cultural Heritage (CH) research. Properties of photographic items, such as position and orientation of the camera, can be automatically estimated using Structure from Motion (SfM) algorithms to enable spatial queries on image repositories. Interactive spatial and temporal browsing of photographs of architecture and corresponding 3D models allows historians to gain knowledge about the development of a city, as well as about the changing interest of photographers in depicting particular buildings over time. In this chapter, we present a classification of phenomena modeling the statistical distribution of historical photographic depictions of architecture. This classification serves the design of specialized visualization methods that show statistical aggregation of photographs in spatial contexts, thus supporting research workflows of art and architectural historians.},
  isbn = {978-3-030-37191-3},
  language = {en},
  series = {Springer {{Series}} on {{Cultural Computing}}}
}



@article{xie_scene_2020,
  title = {Scene Recognition: {{A}} Comprehensive Survey},
  shorttitle = {Scene Recognition},
  author = {Xie, Lin and Lee, Feifei and Liu, Li and Kotani, Koji and Chen, Qiu},
  year = {2020},
  month = jun,
  volume = {102},
  pages = {107205},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2020.107205},
  abstract = {With the success of deep learning in the field of computer vision, object recognition has made important breakthroughs, and its recognition accuracy has been drastically improved. However, the performance of scene recognition is still not sufficient to some extent because of complex configurations. Over the past several years, scene recognition algorithms have undergone important evolution as a result of the development of machine learning and Deep Convolutional Neural Networks (DCNN). This paper reviews many of the most popular and effective approaches to scene recognition, which is expected to create benefits for future research and practical applications. We seek to establish relationships among different algorithms and determine the critical components that lead to remarkable performance. Through the analysis of some representative schemes, motivation and insights are identified, which will help to facilitate the design of better recognition architectures. In addition, current available scene datasets and benchmarks are presented for evaluation and comparison. Finally, potential problems and promising directions are highlighted.},
  file = {/Users/melvinwevers/Dropbox/zotero/Xie et al_2020_Scene recognition.pdf;/Users/melvinwevers/Zotero/storage/VH8B253P/S003132032030011X.html},
  journal = {Pattern Recognition},
  keywords = {Convolutional neural networks,Deep learning,Discriminative region detection,Patch feature encoding,Scene recognition,Spatial layout pattern learning},
  language = {en}
}


@article{zhou_places_2018,
  title = {Places: {{A}} 10 {{Million Image Database}} for {{Scene Recognition}}},
  shorttitle = {Places},
  author = {Zhou, Bolei and Lapedriza, Agata and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
  year = {2018},
  month = jun,
  volume = {40},
  pages = {1452--1464},
  issn = {0162-8828, 2160-9292, 1939-3539},
  doi = {10.1109/TPAMI.2017.2723009},
  abstract = {The rise of multi-million-item dataset initiatives has enabled data-hungry machine learning algorithms to reach nearhuman semantic classification performance at tasks such as visual object and scene recognition. Here we describe the Places Database, a repository of 10 million scene photographs, labeled with scene semantic categories, comprising a large and diverse list of the types of environments encountered in the world. Using the state-of-the-art Convolutional Neural Networks (CNNs), we provide scene classification CNNs (Places-CNNs) as baselines, that significantly outperform the previous approaches. Visualization of the CNNs trained on Places shows that object detectors emerge as an intermediate representation of scene classification. With its high-coverage and high-diversity of exemplars, the Places Database along with the Places-CNNs offer a novel resource to guide future progress on scene recognition problems.},
  file = {/Users/melvinwevers/Zotero/storage/KLAKXDDV/Zhou et al. - 2018 - Places A 10 Million Image Database for Scene Reco.pdf},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  language = {en},
  number = {6}
}




@book{goodfellow_deep_2016,
  title = {Deep {{Learning}}},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year = {2016},
  month = nov,
  publisher = {{The MIT Press}},
  address = {{Cambridge, Massachusetts}},
  abstract = {An introduction to a broad range of topics in deep learning, covering mathematical and conceptual background, deep learning techniques used in industry, and research perspectives.``Written by three experts in the field, Deep Learning is the only comprehensive book on the subject.''\rule{1em}{1pt}Elon Musk, cochair of OpenAI; cofounder and CEO of Tesla and SpaceXDeep learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning. The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and videogames. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models. Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors.},
  isbn = {978-0-262-03561-3},
  language = {English}
}


@article{wevers_visual_2020,
  title = {The Visual Digital Turn: {{Using}} Neural Networks to Study Historical Images},
  shorttitle = {The Visual Digital Turn},
  author = {Wevers, Melvin and Smits, Thomas},
  year = {2020},
  month = apr,
  volume = {35},
  pages = {194--207},
  publisher = {{Oxford Academic}},
  issn = {2055-7671},
  doi = {10.1093/llc/fqy085},
  abstract = {Abstract.  Digital humanities research has focused primarily on the analysis of texts. This emphasis stems from the availability of technology to study digitize},
  file = {/Users/melvinwevers/Zotero/storage/J8GDIDPR/Wevers_Smits_2020_The visual digital turn.pdf;/Users/melvinwevers/Zotero/storage/5MK46DQ2/5296356.html},
  journal = {Digital Scholarship in the Humanities},
  language = {en},
  number = {1}
}


@article{pan_survey_2010,
  title = {A {{Survey}} on {{Transfer Learning}}},
  author = {Pan, Sinno Jialin and Yang, Qiang},
  year = {2010},
  month = oct,
  volume = {22},
  pages = {1345--1359},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2009.191},
  abstract = {A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift. We also explore some potential future issues in transfer learning research.},
  file = {/Users/melvinwevers/Zotero/storage/32INTQGU/5288526.html},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  keywords = {data mining,Data mining,data mining.,inductive transfer learning,knowledge engineering,Knowledge engineering,knowledge transfer,Knowledge transfer,Labeling,learning by example,Learning systems,machine learning,Machine learning,Machine learning algorithms,optimisation,Space technology,survey,Testing,Training data,transductive transfer learning,Transfer learning,unsupervised learning,unsupervised transfer learning},
  number = {10}
}

@inproceedings{madhu2019recognizing,
  title={Recognizing Characters in Art History Using Deep Learning},
  author={Madhu, Prathmesh and Kosti, Ronak and M{\"u}hrenberg, Lara and Bell, Peter and Maier, Andreas and Christlein, Vincent},
  booktitle={Proceedings of the 1st Workshop on Structuring and Understanding of Multimedia heritAge Contents},
  pages={15--22},
  year={2019}
}

@article{petras2017europeana,
  title={Europeana--a Search Engine for Digitised Cultural Heritage Material},
  author={Petras, Vivien and Hill, Timothy and Stiller, Juliane and G{\"a}de, Maria},
  journal={Datenbank-Spektrum},
  volume={17},
  number={1},
  pages={41--46},
  year={2017},
  publisher={Springer}
}

@inproceedings{clough2017europeana,
  title={Europeana: What users search for and why},
  author={Clough, Paul and Hill, Timothy and Paramita, Monica Lestari and Goodale, Paula},
  booktitle={International Conference on Theory and Practice of Digital Libraries},
  pages={207--219},
  year={2017},
  organization={Springer}
}



@article{llamasClassificationArchitecturalHeritage2017,
  title = {Classification of {{Architectural Heritage Images Using Deep Learning Techniques}}},
  author = {Llamas, Jose and M. Lerones, Pedro and Medina, Roberto and Zalama, Eduardo and {G{\'o}mez-Garc{\'i}a-Bermejo}, Jaime},
  year = {2017},
  month = oct,
  volume = {7},
  pages = {992},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  journal = {Applied Sciences},
  keywords = {architectural heritage,convolutional neural network,deep learning,digital documentation,image classification},
  language = {en},
  number = {10}
}


@article{szegedyGoingDeeperConvolutions2014,
  title = {Going {{Deeper}} with {{Convolutions}}},
  author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  year = {2014},
  month = sep,
  archivePrefix = {arXiv},
  eprint = {1409.4842},
  eprinttype = {arxiv},
  journal = {arXiv:1409.4842 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  primaryClass = {cs}
}


@article{yunCutMixRegularizationStrategy2019,
  title = {{{CutMix}}: {{Regularization Strategy}} to {{Train Strong Classifiers}} with {{Localizable Features}}},
  shorttitle = {{{CutMix}}},
  author = {Yun, Sangdoo and Han, Dongyoon and Oh, Seong Joon and Chun, Sanghyuk and Choe, Junsuk and Yoo, Youngjoon},
  year = {2019},
  month = aug,
  archivePrefix = {arXiv},
  eprint = {1905.04899},
  eprinttype = {arxiv},
  journal = {arXiv:1905.04899 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  primaryClass = {cs}
}





@article{zhangMixupEmpiricalRisk2018,
  title = {Mixup: {{Beyond Empirical Risk Minimization}}},
  shorttitle = {Mixup},
  author = {Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N. and {Lopez-Paz}, David},
  year = {2018},
  month = apr,
  archivePrefix = {arXiv},
  eprint = {1710.09412},
  eprinttype = {arxiv},
  journal = {arXiv:1710.09412 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}




@inproceedings{offert2018images,
  title={Images of Image Machines. Visual Interpretability in Computer Vision for Art},
  author={Offert, Fabian},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  year={2018}
}

@article{bell2019ikonographie,
  title={Ikonographie und Interaktion. Computergest{\"u}tzte Analyse von Posen in Bildern der Heilsgeschichte},
  author={Bell, Peter and Impett, Leonardo},
  journal={Das Mittelalter},
  volume={24},
  number={1},
  pages={31--53},
  year={2019},
  publisher={De Gruyter}
}


@article{smithDisciplinedApproachNeural2018a,
  title = {A Disciplined Approach to Neural Network Hyper-Parameters: {{Part}} 1 -- Learning Rate, Batch Size, Momentum, and Weight Decay},
  shorttitle = {A Disciplined Approach to Neural Network Hyper-Parameters},
  author = {Smith, Leslie N.},
  year = {2018},
  month = apr,
  archivePrefix = {arXiv},
  eprint = {1803.09820},
  eprinttype = {arxiv},
  journal = {arXiv:1803.09820 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}




@misc{howard2018fastai,
  title={fastai},
  author={Howard, Jeremy and others},
  year={2018},
  publisher={GitHub},
  howpublished={\url{https://github.com/fastai/fastai}},
}

@article{maiwald2017photogrammetric,
  title={Photogrammetric analysis of historical image repositories for virtual reconstruction in the field of digital humanities},
  author={Maiwald, Ferdinand and Vietze, Theresa and Schneider, Danilo and Henze, Frank and M{\"u}nster, Sander and Niebling, Florian},
  journal={The International Archives of Photogrammetry, Remote Sensing and Spatial Information Sciences},
  volume={42},
  pages={447},
  year={2017},
  publisher={Copernicus GmbH}
}


@article{maiwald2019generation,
  title={GENERATION OF A BENCHMARK DATASET USING HISTORICAL PHOTOGRAPHS FOR AN AUTOMATED EVALUATION OF DIFFERENT FEATURE MATCHING METHODS.},
  author={Maiwald, F},
  journal={International Archives of the Photogrammetry, Remote Sensing \& Spatial Information Sciences},
  year={2019}
}


@inproceedings{Palermo_2012,
  title = {Dating Historical Color Images},
  booktitle = {Computer Vision \textendash{} {{ECCV}} 2012},
  author = {Palermo, Frank and Hays, James and Efros, Alexei A.},
  editor = {Fitzgibbon, Andrew and Lazebnik, Svetlana and Perona, Pietro and Sato, Yoichi and Schmid, Cordelia},
  year = {2012},
  pages = {499--512},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  isbn = {978-3-642-33783-3}
}





@article{rawat_deep_2017,
  title = {Deep {{Convolutional Neural Networks}} for {{Image Classification}}: {{A Comprehensive Review}}},
  shorttitle = {Deep {{Convolutional Neural Networks}} for {{Image Classification}}},
  author = {Rawat, Waseem and Wang, Zenghui},
  year = {2017},
  month = jun,
  volume = {29},
  pages = {2352--2449},
  publisher = {{MIT Press}},
  issn = {0899-7667},
  doi = {10.1162/neco_a_00990},
  abstract = {Convolutional neural networks (CNNs) have been applied to visual tasks since the late 1980s. However, despite a few scattered applications, they were dormant until the mid-2000s when developments in computing power and the advent of large amounts of labeled data, supplemented by improved algorithms, contributed to their advancement and brought them to the forefront of a neural network renaissance that has seen rapid progression since 2012. In this review, which focuses on the application of CNNs to image classification tasks, we cover their development, from their predecessors up to recent state-of-the-art deep learning systems. Along the way, we analyze (1) their early successes, (2) their role in the deep learning renaissance, (3) selected symbolic works that have contributed to their recent popularity, and (4) several improvement attempts by reviewing contributions and challenges of over 300 publications. We also introduce some of their current trends and remaining challenges.},
  file = {/Users/melvinwevers/Zotero/storage/34D5ZDK8/neco_a_00990.html},
  journal = {Neural Computation},
  number = {9}
}


@article{voulodimos_deep_2018,
  title = {Deep {{Learning}} for {{Computer Vision}}: {{A Brief Review}}},
  shorttitle = {Deep {{Learning}} for {{Computer Vision}}},
  author = {Voulodimos, Athanasios and Doulamis, Nikolaos D. and Doulamis, Anastasios and Protopapadakis, Eftychios},
  year = {2018},
  doi = {10.1155/2018/7068349},
  abstract = {Over the last years deep learning methods have been shown to outperform previous state-of-the-art machine learning techniques in several fields, with computer vision being one of the most prominent cases. This review paper provides a brief overview of some of the most significant deep learning schemes used in computer vision problems, that is, Convolutional Neural Networks, Deep Boltzmann Machines and Deep Belief Networks, and Stacked Denoising Autoencoders. A brief account of their history, structure, advantages, and limitations is given, followed by a description of their applications in various computer vision tasks, such as object detection, face recognition, action and activity recognition, and human pose estimation. Finally, a brief overview is given of future directions in designing deep learning schemes for computer vision problems and the challenges involved therein.},
  file = {/Users/melvinwevers/Zotero/storage/FF8D3EV6/Voulodimos et al. - 2018 - Deep Learning for Computer Vision A Brief Review.pdf},
  journal = {Comput. Intell. Neurosci.}
}





